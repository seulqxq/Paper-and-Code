{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cdf7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().resolve().parent  # or .parent.parent 依据你的目录\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from holopart.pipelines.pipeline_holopart import HoloPartPipeline\n",
    "from holopart.inference_utils import hierarchical_extract_geometry, flash_extract_geometry\n",
    "from huggingface_hub import snapshot_download\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29499ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files:  10%|█         | 1/10 [00:01<00:09,  1.07s/it]'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /VAST-AI/HoloPart/resolve/29cdb1417121842c4c4d59b9d283cc734f8c3aec/transformer/diffusion_pytorch_model.safetensors (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1017)')))\"), '(Request ID: 17b67810-b446-41a2-85cf-4e69d8bb0afb)')' thrown while requesting HEAD https://huggingface.co/VAST-AI/HoloPart/resolve/29cdb1417121842c4c4d59b9d283cc734f8c3aec/transformer/diffusion_pytorch_model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Fetching 10 files: 100%|██████████| 10/10 [00:28<00:00,  2.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/d/wsl/seulxia/HoloPart/pretrained_weights/HoloPart'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holopart_weights_dir = \"pretrained_weights/HoloPart\"\n",
    "snapshot_download(repo_id=\"VAST-AI/HoloPart\", local_dir=holopart_weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c75cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 4/4 [00:38<00:00,  9.72s/it]\n"
     ]
    }
   ],
   "source": [
    "HoloPartPipeline = HoloPartPipeline.from_pretrained(holopart_weights_dir).to(device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60797319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HoloPartPipeline {\n",
      "  \"_class_name\": \"HoloPartPipeline\",\n",
      "  \"_diffusers_version\": \"0.35.2\",\n",
      "  \"_name_or_path\": \"pretrained_weights/HoloPart\",\n",
      "  \"part_encoder\": [\n",
      "    \"holopart.models.part_encoders\",\n",
      "    \"PartEncoder\"\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"holopart.schedulers.scheduling_rectified_flow\",\n",
      "    \"RectifiedFlowScheduler\"\n",
      "  ],\n",
      "  \"transformer\": [\n",
      "    \"holopart.models.transformers.triposg_transformer\",\n",
      "    \"TripoSGDiTModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"holopart.models.autoencoders.autoencoder_kl_triposg\",\n",
      "    \"TripoSGVAEModel\"\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(HoloPartPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36673d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PartEncoder' object has no attribute 'name_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mHoloPartPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpart_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_parameters\u001b[49m()\n",
      "File \u001b[0;32m~/miniforge3/envs/holopart/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:273\u001b[0m, in \u001b[0;36mModelMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_dict[name]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# call PyTorch's https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/holopart/lib/python3.10/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PartEncoder' object has no attribute 'name_parameters'"
     ]
    }
   ],
   "source": [
    "HoloPartPipeline.part_encoder.name_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82408da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "各组件参数统计:\n",
      "================================================================================\n",
      "VAE:\n",
      "  总参数: 242,662,017 (242.66M)\n",
      "  可训练参数: 242,662,017 (242.66M)\n",
      "\n",
      "Transformer:\n",
      "  总参数: 1,615,851,328 (1615.85M)\n",
      "  可训练参数: 1,615,851,328 (1615.85M)\n",
      "\n",
      "Part Encoder:\n",
      "  总参数: 56,804,352 (56.80M)\n",
      "  可训练参数: 56,804,352 (56.80M)\n",
      "\n",
      "================================================================================\n",
      "Pipeline总参数: 1,915,317,697 (1915.32M)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 方法1: 查看所有参数的总数量和每个组件的参数数量\n",
    "def count_parameters(model):\n",
    "    \"\"\"统计模型参数数量\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"各组件参数统计:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 统计各个组件\n",
    "components = {\n",
    "    'VAE': HoloPartPipeline.vae,\n",
    "    'Transformer': HoloPartPipeline.transformer,\n",
    "    'Part Encoder': HoloPartPipeline.part_encoder,\n",
    "}\n",
    "\n",
    "total_all = 0\n",
    "for name, component in components.items():\n",
    "    if component is not None:\n",
    "        total, trainable = count_parameters(component)\n",
    "        total_all += total\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  总参数: {total:,} ({total/1e6:.2f}M)\")\n",
    "        print(f\"  可训练参数: {trainable:,} ({trainable/1e6:.2f}M)\")\n",
    "        print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Pipeline总参数: {total_all:,} ({total_all/1e6:.2f}M)\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac6c19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "各组件的配置信息:\n",
      "================================================================================\n",
      "\n",
      "VAE配置:\n",
      "  in_channels: 3\n",
      "  latent_channels: 64\n",
      "  num_attention_heads: 8\n",
      "  width_encoder: 512\n",
      "  width_decoder: 1024\n",
      "  num_layers_encoder: 8\n",
      "  num_layers_decoder: 16\n",
      "  embedding_type: frequency\n",
      "  embed_frequency: 8\n",
      "  embed_include_pi: False\n",
      "  _class_name: TripoSGVAEModel\n",
      "  _diffusers_version: 0.30.3\n",
      "  _name_or_path: pretrained_weights/HoloPart/vae\n",
      "\n",
      "Transformer配置:\n",
      "  num_attention_heads: 16\n",
      "  width: 2048\n",
      "  in_channels: 64\n",
      "  num_layers: 21\n",
      "  cross_attention_dim: 512\n",
      "  cross_attention_2_dim: 512\n",
      "  use_cross_attention: True\n",
      "  use_cross_attention_2: True\n",
      "  _class_name: TripoSGDiTModel\n",
      "  _diffusers_version: 0.30.3\n",
      "  _name_or_path: pretrained_weights/HoloPart/transformer\n",
      "\n",
      "Part Encoder配置:\n",
      "  position_channels: 3\n",
      "  part_feature_channels: 3\n",
      "  whole_feature_channels: 4\n",
      "  dim: 512\n",
      "  num_attention_heads: 8\n",
      "  num_layers: 8\n",
      "  num_tokens: 2048\n",
      "  embedding_type: frequency\n",
      "  embed_frequency: 8\n",
      "  embed_include_pi: False\n",
      "  part_local: True\n",
      "  init_weights: None\n",
      "  noise_level: None\n",
      "  _class_name: PartEncoder\n",
      "  _diffusers_version: 0.30.3\n",
      "  _name_or_path: pretrained_weights/HoloPart/part_encoder\n",
      "\n",
      "Scheduler配置:\n",
      "  num_train_timesteps: 1000\n",
      "  shift: 2\n",
      "  use_dynamic_shifting: False\n",
      "  _class_name: RectifiedFlowScheduler\n",
      "  _diffusers_version: 0.30.3\n"
     ]
    }
   ],
   "source": [
    "# 方法2: 查看各组件的配置\n",
    "print(\"=\" * 80)\n",
    "print(\"各组件的配置信息:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# VAE配置\n",
    "if hasattr(HoloPartPipeline.vae, 'config'):\n",
    "    print(\"\\nVAE配置:\")\n",
    "    for key, value in HoloPartPipeline.vae.config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Transformer配置\n",
    "if hasattr(HoloPartPipeline.transformer, 'config'):\n",
    "    print(\"\\nTransformer配置:\")\n",
    "    for key, value in HoloPartPipeline.transformer.config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Part Encoder配置\n",
    "if hasattr(HoloPartPipeline.part_encoder, 'config'):\n",
    "    print(\"\\nPart Encoder配置:\")\n",
    "    for key, value in HoloPartPipeline.part_encoder.config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Scheduler配置\n",
    "if hasattr(HoloPartPipeline.scheduler, 'config'):\n",
    "    print(\"\\nScheduler配置:\")\n",
    "    for key, value in HoloPartPipeline.scheduler.config.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63737c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attention_kwargs', 'components', 'config', 'config_name', 'device', 'disable_attention_slicing', 'disable_vae_slicing', 'disable_vae_tiling', 'disable_xformers_memory_efficient_attention', 'do_classifier_free_guidance', 'download', 'dtype', 'enable_attention_slicing', 'enable_model_cpu_offload', 'enable_sequential_cpu_offload', 'enable_vae_slicing', 'enable_vae_tiling', 'enable_xformers_memory_efficient_attention', 'encode_context_local', 'extract_init_dict', 'from_config', 'from_pipe', 'from_pretrained', 'fuse_qkv_projections', 'get_config_dict', 'guidance_scale', 'has_compatibles', 'hf_device_map', 'ignore_for_config', 'interrupt', 'load_config', 'maybe_free_model_hooks', 'model_cpu_offload_seq', 'name_or_path', 'num_timesteps', 'numpy_to_pil', 'part_encoder', 'prepare_latents', 'progress_bar', 'push_to_hub', 'register_modules', 'register_to_config', 'remove_all_hooks', 'reset_device_map', 'save_config', 'save_pretrained', 'scheduler', 'set_attention_slice', 'set_progress_bar_config', 'set_use_memory_efficient_attention_xformers', 'to', 'to_json_file', 'to_json_string', 'transformer', 'unfuse_qkv_projections', 'vae']\n"
     ]
    }
   ],
   "source": [
    "# 查看 pipeline 的所有属性\n",
    "print([attr for attr in dir(HoloPartPipeline) if not attr.startswith('_')])\n",
    "\n",
    "# 检查是否有 model 属性\n",
    "if hasattr(HoloPartPipeline, 'model'):\n",
    "    print(\"Pipeline has model attribute\")\n",
    "    model = HoloPartPipeline.model\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.shape)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total model parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5434ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Transformer 组件 ===\n",
      "time_proj.linear_1.weight: torch.Size([8192, 2048])\n",
      "time_proj.linear_1.bias: torch.Size([8192])\n",
      "time_proj.linear_2.weight: torch.Size([2048, 8192])\n",
      "time_proj.linear_2.bias: torch.Size([2048])\n",
      "proj_in.weight: torch.Size([2048, 64])\n",
      "proj_in.bias: torch.Size([2048])\n",
      "blocks.0.norm1.weight: torch.Size([2048])\n",
      "blocks.0.norm1.bias: torch.Size([2048])\n",
      "blocks.0.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.0.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.0.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.0.norm2.weight: torch.Size([2048])\n",
      "blocks.0.norm2.bias: torch.Size([2048])\n",
      "blocks.0.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.0.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.0.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.0.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.0.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.0.norm2_2.weight: torch.Size([2048])\n",
      "blocks.0.norm2_2.bias: torch.Size([2048])\n",
      "blocks.0.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.0.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.0.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.0.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.0.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.0.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.0.norm3.weight: torch.Size([2048])\n",
      "blocks.0.norm3.bias: torch.Size([2048])\n",
      "blocks.0.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.0.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.0.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.0.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.1.norm1.weight: torch.Size([2048])\n",
      "blocks.1.norm1.bias: torch.Size([2048])\n",
      "blocks.1.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.1.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.1.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.1.norm2.weight: torch.Size([2048])\n",
      "blocks.1.norm2.bias: torch.Size([2048])\n",
      "blocks.1.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.1.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.1.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.1.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.1.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.1.norm2_2.weight: torch.Size([2048])\n",
      "blocks.1.norm2_2.bias: torch.Size([2048])\n",
      "blocks.1.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.1.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.1.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.1.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.1.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.1.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.1.norm3.weight: torch.Size([2048])\n",
      "blocks.1.norm3.bias: torch.Size([2048])\n",
      "blocks.1.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.1.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.1.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.1.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.2.norm1.weight: torch.Size([2048])\n",
      "blocks.2.norm1.bias: torch.Size([2048])\n",
      "blocks.2.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.2.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.2.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.2.norm2.weight: torch.Size([2048])\n",
      "blocks.2.norm2.bias: torch.Size([2048])\n",
      "blocks.2.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.2.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.2.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.2.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.2.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.2.norm2_2.weight: torch.Size([2048])\n",
      "blocks.2.norm2_2.bias: torch.Size([2048])\n",
      "blocks.2.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.2.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.2.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.2.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.2.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.2.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.2.norm3.weight: torch.Size([2048])\n",
      "blocks.2.norm3.bias: torch.Size([2048])\n",
      "blocks.2.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.2.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.2.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.2.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.3.norm1.weight: torch.Size([2048])\n",
      "blocks.3.norm1.bias: torch.Size([2048])\n",
      "blocks.3.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.3.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.3.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.3.norm2.weight: torch.Size([2048])\n",
      "blocks.3.norm2.bias: torch.Size([2048])\n",
      "blocks.3.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.3.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.3.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.3.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.3.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.3.norm2_2.weight: torch.Size([2048])\n",
      "blocks.3.norm2_2.bias: torch.Size([2048])\n",
      "blocks.3.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.3.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.3.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.3.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.3.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.3.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.3.norm3.weight: torch.Size([2048])\n",
      "blocks.3.norm3.bias: torch.Size([2048])\n",
      "blocks.3.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.3.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.3.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.3.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.4.norm1.weight: torch.Size([2048])\n",
      "blocks.4.norm1.bias: torch.Size([2048])\n",
      "blocks.4.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.4.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.4.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.4.norm2.weight: torch.Size([2048])\n",
      "blocks.4.norm2.bias: torch.Size([2048])\n",
      "blocks.4.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.4.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.4.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.4.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.4.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.4.norm2_2.weight: torch.Size([2048])\n",
      "blocks.4.norm2_2.bias: torch.Size([2048])\n",
      "blocks.4.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.4.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.4.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.4.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.4.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.4.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.4.norm3.weight: torch.Size([2048])\n",
      "blocks.4.norm3.bias: torch.Size([2048])\n",
      "blocks.4.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.4.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.4.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.4.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.5.norm1.weight: torch.Size([2048])\n",
      "blocks.5.norm1.bias: torch.Size([2048])\n",
      "blocks.5.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.5.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.5.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.5.norm2.weight: torch.Size([2048])\n",
      "blocks.5.norm2.bias: torch.Size([2048])\n",
      "blocks.5.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.5.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.5.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.5.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.5.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.5.norm2_2.weight: torch.Size([2048])\n",
      "blocks.5.norm2_2.bias: torch.Size([2048])\n",
      "blocks.5.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.5.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.5.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.5.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.5.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.5.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.5.norm3.weight: torch.Size([2048])\n",
      "blocks.5.norm3.bias: torch.Size([2048])\n",
      "blocks.5.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.5.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.5.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.5.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.6.norm1.weight: torch.Size([2048])\n",
      "blocks.6.norm1.bias: torch.Size([2048])\n",
      "blocks.6.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.6.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.6.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.6.norm2.weight: torch.Size([2048])\n",
      "blocks.6.norm2.bias: torch.Size([2048])\n",
      "blocks.6.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.6.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.6.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.6.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.6.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.6.norm2_2.weight: torch.Size([2048])\n",
      "blocks.6.norm2_2.bias: torch.Size([2048])\n",
      "blocks.6.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.6.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.6.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.6.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.6.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.6.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.6.norm3.weight: torch.Size([2048])\n",
      "blocks.6.norm3.bias: torch.Size([2048])\n",
      "blocks.6.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.6.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.6.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.6.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.7.norm1.weight: torch.Size([2048])\n",
      "blocks.7.norm1.bias: torch.Size([2048])\n",
      "blocks.7.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.7.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.7.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.7.norm2.weight: torch.Size([2048])\n",
      "blocks.7.norm2.bias: torch.Size([2048])\n",
      "blocks.7.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.7.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.7.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.7.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.7.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.7.norm2_2.weight: torch.Size([2048])\n",
      "blocks.7.norm2_2.bias: torch.Size([2048])\n",
      "blocks.7.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.7.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.7.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.7.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.7.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.7.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.7.norm3.weight: torch.Size([2048])\n",
      "blocks.7.norm3.bias: torch.Size([2048])\n",
      "blocks.7.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.7.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.7.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.7.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.8.norm1.weight: torch.Size([2048])\n",
      "blocks.8.norm1.bias: torch.Size([2048])\n",
      "blocks.8.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.8.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.8.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.8.norm2.weight: torch.Size([2048])\n",
      "blocks.8.norm2.bias: torch.Size([2048])\n",
      "blocks.8.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.8.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.8.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.8.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.8.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.8.norm2_2.weight: torch.Size([2048])\n",
      "blocks.8.norm2_2.bias: torch.Size([2048])\n",
      "blocks.8.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.8.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.8.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.8.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.8.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.8.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.8.norm3.weight: torch.Size([2048])\n",
      "blocks.8.norm3.bias: torch.Size([2048])\n",
      "blocks.8.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.8.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.8.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.8.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.9.norm1.weight: torch.Size([2048])\n",
      "blocks.9.norm1.bias: torch.Size([2048])\n",
      "blocks.9.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.9.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.9.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.9.norm2.weight: torch.Size([2048])\n",
      "blocks.9.norm2.bias: torch.Size([2048])\n",
      "blocks.9.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.9.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.9.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.9.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.9.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.9.norm2_2.weight: torch.Size([2048])\n",
      "blocks.9.norm2_2.bias: torch.Size([2048])\n",
      "blocks.9.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.9.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.9.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.9.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.9.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.9.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.9.norm3.weight: torch.Size([2048])\n",
      "blocks.9.norm3.bias: torch.Size([2048])\n",
      "blocks.9.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.9.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.9.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.9.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.10.norm1.weight: torch.Size([2048])\n",
      "blocks.10.norm1.bias: torch.Size([2048])\n",
      "blocks.10.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.10.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.10.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.10.norm2.weight: torch.Size([2048])\n",
      "blocks.10.norm2.bias: torch.Size([2048])\n",
      "blocks.10.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.10.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.10.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.10.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.10.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.10.norm2_2.weight: torch.Size([2048])\n",
      "blocks.10.norm2_2.bias: torch.Size([2048])\n",
      "blocks.10.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.10.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.10.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.10.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.10.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.10.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.10.norm3.weight: torch.Size([2048])\n",
      "blocks.10.norm3.bias: torch.Size([2048])\n",
      "blocks.10.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.10.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.10.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.10.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.11.norm1.weight: torch.Size([2048])\n",
      "blocks.11.norm1.bias: torch.Size([2048])\n",
      "blocks.11.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.11.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.11.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.11.norm2.weight: torch.Size([2048])\n",
      "blocks.11.norm2.bias: torch.Size([2048])\n",
      "blocks.11.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.11.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.11.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.11.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.11.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.11.norm2_2.weight: torch.Size([2048])\n",
      "blocks.11.norm2_2.bias: torch.Size([2048])\n",
      "blocks.11.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.11.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.11.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.11.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.11.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.11.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.11.norm3.weight: torch.Size([2048])\n",
      "blocks.11.norm3.bias: torch.Size([2048])\n",
      "blocks.11.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.11.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.11.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.11.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.11.skip_norm.weight: torch.Size([2048])\n",
      "blocks.11.skip_norm.bias: torch.Size([2048])\n",
      "blocks.11.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.11.skip_linear.bias: torch.Size([2048])\n",
      "blocks.12.norm1.weight: torch.Size([2048])\n",
      "blocks.12.norm1.bias: torch.Size([2048])\n",
      "blocks.12.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.12.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.12.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.12.norm2.weight: torch.Size([2048])\n",
      "blocks.12.norm2.bias: torch.Size([2048])\n",
      "blocks.12.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.12.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.12.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.12.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.12.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.12.norm2_2.weight: torch.Size([2048])\n",
      "blocks.12.norm2_2.bias: torch.Size([2048])\n",
      "blocks.12.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.12.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.12.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.12.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.12.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.12.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.12.norm3.weight: torch.Size([2048])\n",
      "blocks.12.norm3.bias: torch.Size([2048])\n",
      "blocks.12.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.12.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.12.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.12.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.12.skip_norm.weight: torch.Size([2048])\n",
      "blocks.12.skip_norm.bias: torch.Size([2048])\n",
      "blocks.12.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.12.skip_linear.bias: torch.Size([2048])\n",
      "blocks.13.norm1.weight: torch.Size([2048])\n",
      "blocks.13.norm1.bias: torch.Size([2048])\n",
      "blocks.13.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.13.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.13.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.13.norm2.weight: torch.Size([2048])\n",
      "blocks.13.norm2.bias: torch.Size([2048])\n",
      "blocks.13.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.13.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.13.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.13.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.13.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.13.norm2_2.weight: torch.Size([2048])\n",
      "blocks.13.norm2_2.bias: torch.Size([2048])\n",
      "blocks.13.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.13.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.13.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.13.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.13.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.13.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.13.norm3.weight: torch.Size([2048])\n",
      "blocks.13.norm3.bias: torch.Size([2048])\n",
      "blocks.13.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.13.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.13.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.13.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.13.skip_norm.weight: torch.Size([2048])\n",
      "blocks.13.skip_norm.bias: torch.Size([2048])\n",
      "blocks.13.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.13.skip_linear.bias: torch.Size([2048])\n",
      "blocks.14.norm1.weight: torch.Size([2048])\n",
      "blocks.14.norm1.bias: torch.Size([2048])\n",
      "blocks.14.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.14.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.14.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.14.norm2.weight: torch.Size([2048])\n",
      "blocks.14.norm2.bias: torch.Size([2048])\n",
      "blocks.14.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.14.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.14.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.14.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.14.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.14.norm2_2.weight: torch.Size([2048])\n",
      "blocks.14.norm2_2.bias: torch.Size([2048])\n",
      "blocks.14.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.14.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.14.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.14.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.14.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.14.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.14.norm3.weight: torch.Size([2048])\n",
      "blocks.14.norm3.bias: torch.Size([2048])\n",
      "blocks.14.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.14.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.14.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.14.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.14.skip_norm.weight: torch.Size([2048])\n",
      "blocks.14.skip_norm.bias: torch.Size([2048])\n",
      "blocks.14.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.14.skip_linear.bias: torch.Size([2048])\n",
      "blocks.15.norm1.weight: torch.Size([2048])\n",
      "blocks.15.norm1.bias: torch.Size([2048])\n",
      "blocks.15.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.15.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.15.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.15.norm2.weight: torch.Size([2048])\n",
      "blocks.15.norm2.bias: torch.Size([2048])\n",
      "blocks.15.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.15.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.15.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.15.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.15.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.15.norm2_2.weight: torch.Size([2048])\n",
      "blocks.15.norm2_2.bias: torch.Size([2048])\n",
      "blocks.15.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.15.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.15.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.15.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.15.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.15.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.15.norm3.weight: torch.Size([2048])\n",
      "blocks.15.norm3.bias: torch.Size([2048])\n",
      "blocks.15.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.15.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.15.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.15.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.15.skip_norm.weight: torch.Size([2048])\n",
      "blocks.15.skip_norm.bias: torch.Size([2048])\n",
      "blocks.15.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.15.skip_linear.bias: torch.Size([2048])\n",
      "blocks.16.norm1.weight: torch.Size([2048])\n",
      "blocks.16.norm1.bias: torch.Size([2048])\n",
      "blocks.16.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.16.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.16.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.16.norm2.weight: torch.Size([2048])\n",
      "blocks.16.norm2.bias: torch.Size([2048])\n",
      "blocks.16.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.16.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.16.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.16.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.16.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.16.norm2_2.weight: torch.Size([2048])\n",
      "blocks.16.norm2_2.bias: torch.Size([2048])\n",
      "blocks.16.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.16.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.16.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.16.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.16.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.16.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.16.norm3.weight: torch.Size([2048])\n",
      "blocks.16.norm3.bias: torch.Size([2048])\n",
      "blocks.16.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.16.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.16.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.16.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.16.skip_norm.weight: torch.Size([2048])\n",
      "blocks.16.skip_norm.bias: torch.Size([2048])\n",
      "blocks.16.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.16.skip_linear.bias: torch.Size([2048])\n",
      "blocks.17.norm1.weight: torch.Size([2048])\n",
      "blocks.17.norm1.bias: torch.Size([2048])\n",
      "blocks.17.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.17.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.17.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.17.norm2.weight: torch.Size([2048])\n",
      "blocks.17.norm2.bias: torch.Size([2048])\n",
      "blocks.17.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.17.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.17.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.17.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.17.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.17.norm2_2.weight: torch.Size([2048])\n",
      "blocks.17.norm2_2.bias: torch.Size([2048])\n",
      "blocks.17.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.17.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.17.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.17.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.17.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.17.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.17.norm3.weight: torch.Size([2048])\n",
      "blocks.17.norm3.bias: torch.Size([2048])\n",
      "blocks.17.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.17.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.17.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.17.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.17.skip_norm.weight: torch.Size([2048])\n",
      "blocks.17.skip_norm.bias: torch.Size([2048])\n",
      "blocks.17.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.17.skip_linear.bias: torch.Size([2048])\n",
      "blocks.18.norm1.weight: torch.Size([2048])\n",
      "blocks.18.norm1.bias: torch.Size([2048])\n",
      "blocks.18.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.18.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.18.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.18.norm2.weight: torch.Size([2048])\n",
      "blocks.18.norm2.bias: torch.Size([2048])\n",
      "blocks.18.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.18.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.18.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.18.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.18.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.18.norm2_2.weight: torch.Size([2048])\n",
      "blocks.18.norm2_2.bias: torch.Size([2048])\n",
      "blocks.18.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.18.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.18.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.18.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.18.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.18.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.18.norm3.weight: torch.Size([2048])\n",
      "blocks.18.norm3.bias: torch.Size([2048])\n",
      "blocks.18.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.18.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.18.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.18.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.18.skip_norm.weight: torch.Size([2048])\n",
      "blocks.18.skip_norm.bias: torch.Size([2048])\n",
      "blocks.18.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.18.skip_linear.bias: torch.Size([2048])\n",
      "blocks.19.norm1.weight: torch.Size([2048])\n",
      "blocks.19.norm1.bias: torch.Size([2048])\n",
      "blocks.19.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.19.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.19.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.19.norm2.weight: torch.Size([2048])\n",
      "blocks.19.norm2.bias: torch.Size([2048])\n",
      "blocks.19.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.19.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.19.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.19.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.19.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.19.norm2_2.weight: torch.Size([2048])\n",
      "blocks.19.norm2_2.bias: torch.Size([2048])\n",
      "blocks.19.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.19.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.19.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.19.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.19.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.19.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.19.norm3.weight: torch.Size([2048])\n",
      "blocks.19.norm3.bias: torch.Size([2048])\n",
      "blocks.19.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.19.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.19.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.19.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.19.skip_norm.weight: torch.Size([2048])\n",
      "blocks.19.skip_norm.bias: torch.Size([2048])\n",
      "blocks.19.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.19.skip_linear.bias: torch.Size([2048])\n",
      "blocks.20.norm1.weight: torch.Size([2048])\n",
      "blocks.20.norm1.bias: torch.Size([2048])\n",
      "blocks.20.attn1.norm_q.weight: torch.Size([128])\n",
      "blocks.20.attn1.norm_k.weight: torch.Size([128])\n",
      "blocks.20.attn1.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn1.to_k.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn1.to_v.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn1.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn1.to_out.0.bias: torch.Size([2048])\n",
      "blocks.20.norm2.weight: torch.Size([2048])\n",
      "blocks.20.norm2.bias: torch.Size([2048])\n",
      "blocks.20.attn2.norm_q.weight: torch.Size([128])\n",
      "blocks.20.attn2.norm_k.weight: torch.Size([128])\n",
      "blocks.20.attn2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.20.attn2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.20.attn2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.20.norm2_2.weight: torch.Size([2048])\n",
      "blocks.20.norm2_2.bias: torch.Size([2048])\n",
      "blocks.20.attn2_2.norm_q.weight: torch.Size([128])\n",
      "blocks.20.attn2_2.norm_k.weight: torch.Size([128])\n",
      "blocks.20.attn2_2.to_q.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn2_2.to_k.weight: torch.Size([2048, 512])\n",
      "blocks.20.attn2_2.to_v.weight: torch.Size([2048, 512])\n",
      "blocks.20.attn2_2.to_out.0.weight: torch.Size([2048, 2048])\n",
      "blocks.20.attn2_2.to_out.0.bias: torch.Size([2048])\n",
      "blocks.20.norm3.weight: torch.Size([2048])\n",
      "blocks.20.norm3.bias: torch.Size([2048])\n",
      "blocks.20.ff.net.0.proj.weight: torch.Size([8192, 2048])\n",
      "blocks.20.ff.net.0.proj.bias: torch.Size([8192])\n",
      "blocks.20.ff.net.2.weight: torch.Size([2048, 8192])\n",
      "blocks.20.ff.net.2.bias: torch.Size([2048])\n",
      "blocks.20.skip_norm.weight: torch.Size([2048])\n",
      "blocks.20.skip_norm.bias: torch.Size([2048])\n",
      "blocks.20.skip_linear.weight: torch.Size([2048, 4096])\n",
      "blocks.20.skip_linear.bias: torch.Size([2048])\n",
      "norm_out.weight: torch.Size([2048])\n",
      "norm_out.bias: torch.Size([2048])\n",
      "proj_out.weight: torch.Size([64, 2048])\n",
      "proj_out.bias: torch.Size([64])\n",
      "Transformer 总参数: 1,615,851,328\n",
      "\n",
      "=== VAE 组件 ===\n",
      "encoder.proj_in.weight: torch.Size([512, 54])\n",
      "encoder.proj_in.bias: torch.Size([512])\n",
      "encoder.blocks.0.norm2.weight: torch.Size([512])\n",
      "encoder.blocks.0.norm2.bias: torch.Size([512])\n",
      "encoder.blocks.0.attn2.norm_cross.weight: torch.Size([512])\n",
      "encoder.blocks.0.attn2.norm_cross.bias: torch.Size([512])\n",
      "encoder.blocks.0.attn2.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.0.attn2.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.0.attn2.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.0.attn2.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.0.attn2.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.0.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.0.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.0.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.0.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.0.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.0.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.1.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.1.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.1.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.1.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.1.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.1.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.1.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.1.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.1.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.1.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.1.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.1.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.1.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.2.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.2.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.2.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.2.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.2.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.2.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.2.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.2.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.2.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.2.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.2.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.2.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.2.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.3.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.3.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.3.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.3.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.3.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.3.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.3.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.3.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.3.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.3.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.3.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.3.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.3.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.4.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.4.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.4.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.4.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.4.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.4.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.4.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.4.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.4.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.4.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.4.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.4.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.4.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.5.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.5.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.5.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.5.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.5.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.5.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.5.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.5.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.5.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.5.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.5.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.5.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.5.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.6.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.6.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.6.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.6.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.6.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.6.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.6.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.6.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.6.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.6.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.6.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.6.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.6.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.7.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.7.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.7.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.7.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.7.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.7.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.7.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.7.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.7.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.7.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.7.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.7.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.7.ff.net.2.bias: torch.Size([512])\n",
      "encoder.blocks.8.norm1.weight: torch.Size([512])\n",
      "encoder.blocks.8.norm1.bias: torch.Size([512])\n",
      "encoder.blocks.8.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder.blocks.8.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder.blocks.8.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder.blocks.8.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder.blocks.8.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder.blocks.8.norm3.weight: torch.Size([512])\n",
      "encoder.blocks.8.norm3.bias: torch.Size([512])\n",
      "encoder.blocks.8.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder.blocks.8.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder.blocks.8.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder.blocks.8.ff.net.2.bias: torch.Size([512])\n",
      "encoder.norm_out.weight: torch.Size([512])\n",
      "encoder.norm_out.bias: torch.Size([512])\n",
      "decoder.blocks.0.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.0.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.0.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.0.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.0.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.0.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.0.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.0.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.0.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.0.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.0.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.0.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.0.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.1.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.1.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.1.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.1.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.1.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.1.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.1.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.1.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.1.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.1.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.1.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.1.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.1.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.2.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.2.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.2.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.2.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.2.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.2.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.2.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.2.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.2.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.2.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.2.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.2.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.2.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.3.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.3.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.3.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.3.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.3.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.3.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.3.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.3.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.3.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.3.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.3.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.3.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.3.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.4.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.4.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.4.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.4.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.4.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.4.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.4.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.4.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.4.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.4.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.4.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.4.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.4.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.5.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.5.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.5.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.5.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.5.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.5.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.5.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.5.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.5.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.5.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.5.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.5.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.5.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.6.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.6.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.6.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.6.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.6.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.6.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.6.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.6.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.6.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.6.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.6.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.6.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.6.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.7.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.7.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.7.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.7.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.7.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.7.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.7.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.7.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.7.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.7.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.7.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.7.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.7.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.8.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.8.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.8.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.8.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.8.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.8.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.8.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.8.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.8.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.8.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.8.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.8.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.8.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.9.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.9.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.9.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.9.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.9.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.9.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.9.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.9.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.9.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.9.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.9.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.9.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.9.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.10.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.10.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.10.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.10.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.10.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.10.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.10.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.10.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.10.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.10.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.10.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.10.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.10.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.11.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.11.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.11.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.11.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.11.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.11.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.11.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.11.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.11.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.11.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.11.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.11.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.11.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.12.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.12.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.12.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.12.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.12.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.12.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.12.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.12.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.12.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.12.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.12.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.12.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.12.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.13.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.13.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.13.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.13.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.13.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.13.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.13.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.13.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.13.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.13.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.13.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.13.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.13.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.14.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.14.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.14.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.14.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.14.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.14.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.14.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.14.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.14.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.14.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.14.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.14.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.14.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.15.norm1.weight: torch.Size([1024])\n",
      "decoder.blocks.15.norm1.bias: torch.Size([1024])\n",
      "decoder.blocks.15.attn1.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.15.attn1.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.15.attn1.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.15.attn1.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.15.attn1.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.15.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.15.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.15.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.15.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.15.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.15.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.blocks.16.norm2.weight: torch.Size([1024])\n",
      "decoder.blocks.16.norm2.bias: torch.Size([1024])\n",
      "decoder.blocks.16.attn2.norm_cross.weight: torch.Size([1024])\n",
      "decoder.blocks.16.attn2.norm_cross.bias: torch.Size([1024])\n",
      "decoder.blocks.16.attn2.to_q.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.16.attn2.to_k.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.16.attn2.to_v.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.16.attn2.to_out.0.weight: torch.Size([1024, 1024])\n",
      "decoder.blocks.16.attn2.to_out.0.bias: torch.Size([1024])\n",
      "decoder.blocks.16.norm3.weight: torch.Size([1024])\n",
      "decoder.blocks.16.norm3.bias: torch.Size([1024])\n",
      "decoder.blocks.16.ff.net.0.proj.weight: torch.Size([4096, 1024])\n",
      "decoder.blocks.16.ff.net.0.proj.bias: torch.Size([4096])\n",
      "decoder.blocks.16.ff.net.2.weight: torch.Size([1024, 4096])\n",
      "decoder.blocks.16.ff.net.2.bias: torch.Size([1024])\n",
      "decoder.proj_query.weight: torch.Size([1024, 51])\n",
      "decoder.proj_query.bias: torch.Size([1024])\n",
      "decoder.norm_out.weight: torch.Size([1024])\n",
      "decoder.norm_out.bias: torch.Size([1024])\n",
      "decoder.proj_out.weight: torch.Size([1, 1024])\n",
      "decoder.proj_out.bias: torch.Size([1])\n",
      "quant.weight: torch.Size([128, 512])\n",
      "quant.bias: torch.Size([128])\n",
      "post_quant.weight: torch.Size([1024, 64])\n",
      "post_quant.bias: torch.Size([1024])\n",
      "VAE 总参数: 242,662,017\n",
      "\n",
      "=== Part Encoder 组件 ===\n",
      "encoder_local.proj_in.weight: torch.Size([512, 54])\n",
      "encoder_local.proj_in.bias: torch.Size([512])\n",
      "encoder_local.blocks.0.norm2.weight: torch.Size([512])\n",
      "encoder_local.blocks.0.norm2.bias: torch.Size([512])\n",
      "encoder_local.blocks.0.attn2.norm_cross.weight: torch.Size([512])\n",
      "encoder_local.blocks.0.attn2.norm_cross.bias: torch.Size([512])\n",
      "encoder_local.blocks.0.attn2.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.0.attn2.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.0.attn2.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.0.attn2.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.0.attn2.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.0.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.0.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.0.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.0.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.0.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.0.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.1.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.1.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.1.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.1.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.1.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.1.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.1.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.1.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.1.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.1.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.1.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.1.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.1.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.2.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.2.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.2.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.2.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.2.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.2.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.2.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.2.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.2.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.2.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.2.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.2.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.2.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.3.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.3.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.3.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.3.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.3.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.3.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.3.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.3.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.3.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.3.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.3.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.3.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.3.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.4.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.4.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.4.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.4.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.4.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.4.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.4.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.4.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.4.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.4.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.4.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.4.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.4.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.5.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.5.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.5.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.5.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.5.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.5.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.5.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.5.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.5.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.5.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.5.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.5.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.5.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.6.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.6.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.6.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.6.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.6.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.6.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.6.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.6.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.6.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.6.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.6.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.6.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.6.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.7.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.7.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.7.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.7.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.7.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.7.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.7.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.7.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.7.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.7.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.7.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.7.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.7.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.blocks.8.norm1.weight: torch.Size([512])\n",
      "encoder_local.blocks.8.norm1.bias: torch.Size([512])\n",
      "encoder_local.blocks.8.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.8.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.8.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.8.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_local.blocks.8.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_local.blocks.8.norm3.weight: torch.Size([512])\n",
      "encoder_local.blocks.8.norm3.bias: torch.Size([512])\n",
      "encoder_local.blocks.8.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_local.blocks.8.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_local.blocks.8.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_local.blocks.8.ff.net.2.bias: torch.Size([512])\n",
      "encoder_local.norm_out.weight: torch.Size([512])\n",
      "encoder_local.norm_out.bias: torch.Size([512])\n",
      "encoder_context.q_proj_in.weight: torch.Size([512, 54])\n",
      "encoder_context.q_proj_in.bias: torch.Size([512])\n",
      "encoder_context.kv_proj_in.weight: torch.Size([512, 55])\n",
      "encoder_context.kv_proj_in.bias: torch.Size([512])\n",
      "encoder_context.blocks.0.norm2.weight: torch.Size([512])\n",
      "encoder_context.blocks.0.norm2.bias: torch.Size([512])\n",
      "encoder_context.blocks.0.attn2.norm_cross.weight: torch.Size([512])\n",
      "encoder_context.blocks.0.attn2.norm_cross.bias: torch.Size([512])\n",
      "encoder_context.blocks.0.attn2.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.0.attn2.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.0.attn2.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.0.attn2.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.0.attn2.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.0.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.0.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.0.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.0.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.0.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.0.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.1.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.1.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.1.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.1.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.1.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.1.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.1.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.1.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.1.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.1.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.1.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.1.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.1.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.2.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.2.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.2.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.2.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.2.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.2.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.2.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.2.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.2.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.2.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.2.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.2.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.2.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.3.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.3.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.3.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.3.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.3.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.3.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.3.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.3.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.3.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.3.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.3.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.3.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.3.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.4.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.4.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.4.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.4.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.4.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.4.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.4.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.4.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.4.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.4.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.4.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.4.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.4.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.5.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.5.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.5.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.5.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.5.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.5.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.5.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.5.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.5.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.5.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.5.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.5.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.5.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.6.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.6.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.6.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.6.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.6.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.6.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.6.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.6.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.6.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.6.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.6.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.6.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.6.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.7.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.7.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.7.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.7.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.7.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.7.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.7.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.7.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.7.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.7.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.7.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.7.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.7.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.blocks.8.norm1.weight: torch.Size([512])\n",
      "encoder_context.blocks.8.norm1.bias: torch.Size([512])\n",
      "encoder_context.blocks.8.attn1.to_q.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.8.attn1.to_k.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.8.attn1.to_v.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.8.attn1.to_out.0.weight: torch.Size([512, 512])\n",
      "encoder_context.blocks.8.attn1.to_out.0.bias: torch.Size([512])\n",
      "encoder_context.blocks.8.norm3.weight: torch.Size([512])\n",
      "encoder_context.blocks.8.norm3.bias: torch.Size([512])\n",
      "encoder_context.blocks.8.ff.net.0.proj.weight: torch.Size([2048, 512])\n",
      "encoder_context.blocks.8.ff.net.0.proj.bias: torch.Size([2048])\n",
      "encoder_context.blocks.8.ff.net.2.weight: torch.Size([512, 2048])\n",
      "encoder_context.blocks.8.ff.net.2.bias: torch.Size([512])\n",
      "encoder_context.norm_out.weight: torch.Size([512])\n",
      "encoder_context.norm_out.bias: torch.Size([512])\n",
      "Part Encoder 总参数: 56,804,352\n",
      "\n",
      "=== 总参数统计 ===\n",
      "transformer: 1,615,851,328 参数\n",
      "vae: 242,662,017 参数\n",
      "part_encoder: 56,804,352 参数\n",
      "所有组件总参数: 1,915,317,697\n"
     ]
    }
   ],
   "source": [
    "# 检查 transformer 组件（很可能是主要的模型）\n",
    "if hasattr(HoloPartPipeline, 'transformer'):\n",
    "    print(\"=== Transformer 组件 ===\")\n",
    "    if hasattr(HoloPartPipeline.transformer, 'named_parameters'):\n",
    "        total_params = 0\n",
    "        for name, param in HoloPartPipeline.transformer.named_parameters():\n",
    "            print(f\"{name}: {param.shape}\")\n",
    "            total_params += param.numel()\n",
    "        print(f\"Transformer 总参数: {total_params:,}\")\n",
    "    else:\n",
    "        print(\"Transformer 没有 named_parameters 方法\")\n",
    "\n",
    "# 检查 VAE 组件\n",
    "if hasattr(HoloPartPipeline, 'vae'):\n",
    "    print(\"\\n=== VAE 组件 ===\")\n",
    "    if hasattr(HoloPartPipeline.vae, 'named_parameters'):\n",
    "        total_params = 0\n",
    "        for name, param in HoloPartPipeline.vae.named_parameters():\n",
    "            print(f\"{name}: {param.shape}\")\n",
    "            total_params += param.numel()\n",
    "        print(f\"VAE 总参数: {total_params:,}\")\n",
    "    else:\n",
    "        print(\"VAE 没有 named_parameters 方法\")\n",
    "\n",
    "# 检查 part_encoder 组件\n",
    "if hasattr(HoloPartPipeline, 'part_encoder'):\n",
    "    print(\"\\n=== Part Encoder 组件 ===\")\n",
    "    if hasattr(HoloPartPipeline.part_encoder, 'named_parameters'):\n",
    "        total_params = 0\n",
    "        for name, param in HoloPartPipeline.part_encoder.named_parameters():\n",
    "            print(f\"{name}: {param.shape}\")\n",
    "            total_params += param.numel()\n",
    "        print(f\"Part Encoder 总参数: {total_params:,}\")\n",
    "    else:\n",
    "        print(\"Part Encoder 没有 named_parameters 方法\")\n",
    "\n",
    "# 计算所有组件的总参数\n",
    "print(\"\\n=== 总参数统计 ===\")\n",
    "total_all_params = 0\n",
    "components = []\n",
    "\n",
    "for attr in ['transformer', 'vae', 'part_encoder']:\n",
    "    if hasattr(HoloPartPipeline, attr):\n",
    "        component = getattr(HoloPartPipeline, attr)\n",
    "        if hasattr(component, 'parameters'):\n",
    "            component_params = sum(p.numel() for p in component.parameters())\n",
    "            components.append((attr, component_params))\n",
    "            total_all_params += component_params\n",
    "\n",
    "for name, params in components:\n",
    "    print(f\"{name}: {params:,} 参数\")\n",
    "\n",
    "print(f\"所有组件总参数: {total_all_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b506c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
